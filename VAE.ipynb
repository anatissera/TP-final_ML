{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2805a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.io import loadmat\n",
    "import wfdb\n",
    "from wfdb import rdrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef4b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train_ecg_vae_reutilice import ECGDataset, ECG_VAE, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e77ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16 - Loss: 9617397089213.7285 (Recon 0.2260, KLD 126.6771)\n",
      "Epoch 2/16 - Loss: 147356917007036704184336384.0000 (Recon 0.1953, KLD 165.2787)\n",
      "Epoch 3/16 - Loss: 3747946700.5763 (Recon 0.1680, KLD 143.4911)\n",
      "Epoch 4/16 - Loss: 1143578589801997696.0000 (Recon 0.2545, KLD 156.9068)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m vae\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     22\u001b[0m tot_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m     x_hat, mu, logv \u001b[38;5;241m=\u001b[39m vae(x)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TP-final_ML\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:493\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TP-final_ML\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:424\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TP-final_ML\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1171\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1164\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1171\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TP-final_ML\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TP-final_ML\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TP-final_ML\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TP-final_ML\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TP-final_ML\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# PTB_DIR = 'data/ptb-xl'\n",
    "# CH_DIR  = 'data/ChapmanShaoxing'\n",
    "# # Hyperparams\n",
    "# batch_size = 16\n",
    "# epochs = 16\n",
    "# lr = 1e-3\n",
    "# z_dim = 16\n",
    "# seq_len = 5000\n",
    "\n",
    "# # Dataset & Loader\n",
    "# ds = ECGDataset(PTB_DIR, CH_DIR, sample_length=seq_len)\n",
    "# loader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# # Model, optim\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# vae = ECG_VAE(z_dim=z_dim, seq_len=seq_len).to(device)\n",
    "# opt = optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "# # Train\n",
    "# for ep in range(1, epochs+1):\n",
    "#     vae.train()\n",
    "#     tot_loss = 0\n",
    "#     for batch in loader:\n",
    "#         x = batch.to(device)\n",
    "#         x_hat, mu, logv = vae(x)\n",
    "#         loss, recon, kld = loss_fn(x, x_hat, mu, logv)\n",
    "#         opt.zero_grad(); loss.backward(); opt.step()\n",
    "#         tot_loss += loss.item()\n",
    "#     print(f\"Epoch {ep}/{epochs} - Loss: {tot_loss/len(loader):.4f} (Recon {recon:.4f}, KLD {kld:.4f})\")\n",
    "# # Guardar\n",
    "# torch.save(vae.state_dict(), 'ecg_vae.pth')\n",
    "# print(\"Modelo guardado en ecg_vae.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b77f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.io import loadmat\n",
    "import wfdb\n",
    "from wfdb import rdrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449dc577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAE import ECGDataset, ECG_VAE, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "PTB_DIR='data/ptb-xl'; CH_DIR='data/ChapmanShaoxing'\n",
    "batch=16; epochs=15; lr=1e-3; z_dim=16; seq_len=5000\n",
    "# dataset completo\n",
    "ds=ECGDataset(PTB_DIR,CH_DIR,seq_len)\n",
    "# split: 80% train, 10% val, 10% test\n",
    "n=len(ds); n_test=int(0.1*n); n_val=int(0.1*n); n_train=n-n_val-n_test\n",
    "ds_train, ds_val, ds_test = random_split(ds, [n_train,n_val,n_test])\n",
    "loader_tr=DataLoader(ds_train,batch,shuffle=True,num_workers=4)\n",
    "loader_val=DataLoader(ds_val,batch,shuffle=False,num_workers=2)\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vae=ECG_VAE(z_dim=z_dim, seq_len=seq_len).to(device)\n",
    "opt=optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "best_val=float('inf')\n",
    "for ep in range(1,epochs+1):\n",
    "    vae.train(); train_loss=0\n",
    "    for xb in loader_tr:\n",
    "        xb=xb.to(device)\n",
    "        xh, mu, lv=vae(xb)\n",
    "        loss,_,_ = loss_fn(xb,xh,mu,lv)\n",
    "        opt.zero_grad(); loss.backward();\n",
    "        nn.utils.clip_grad_norm_(vae.parameters(),1.0)\n",
    "        opt.step(); train_loss+=loss.item()\n",
    "    train_loss/=len(loader_tr)\n",
    "    # validación\n",
    "    vae.eval(); val_loss=0\n",
    "    with torch.no_grad():\n",
    "        for xb in loader_val:\n",
    "            xb=xb.to(device)\n",
    "            xh,mu,lv=vae(xb)\n",
    "            loss,_,_=loss_fn(xb,xh,mu,lv)\n",
    "            val_loss+=loss.item()\n",
    "    val_loss/=len(loader_val)\n",
    "    print(f\"Epoch {ep}/{epochs} - Train L: {train_loss:.4f}  Val L: {val_loss:.4f}\")\n",
    "    if val_loss<best_val:\n",
    "        best_val=val_loss\n",
    "        torch.save(vae.state_dict(),'ecg_vae_best.pth')\n",
    "print(\"Entrenamiento completo. Mejor modelo en ecg_vae_best.pth\")\n",
    "# test: MAE sobre ds_test\n",
    "from torch.utils.data import DataLoader\n",
    "loader_te=DataLoader(ds_test,batch,shuffle=False)\n",
    "tot_mae=[]\n",
    "vae.load_state_dict(torch.load('ecg_vae_best.pth',map_location=device))\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    for xb in loader_te:\n",
    "        xb=xb.to(device)\n",
    "        xh,_,_=vae(xb)\n",
    "        mae=torch.abs(xh-xb).mean(dim=(1,2)).cpu().numpy()\n",
    "        tot_mae.extend(mae.tolist())\n",
    "print(f\"MAE promedio normales test: {np.mean(tot_mae):.4f}\")\n",
    "# ds_test contiene sólo normales. Anómalos se evalúan en script aparte."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP-final_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
