{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2805a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.io import loadmat\n",
    "import wfdb\n",
    "from wfdb import rdrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef4b9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "764f25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train_ecg_vae_reutilice import ECGDataset, ECG_VAE, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e77ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTB_DIR = 'data/ptb-xl'\n",
    "# CH_DIR  = 'data/ChapmanShaoxing'\n",
    "# # Hyperparams\n",
    "# batch_size = 16\n",
    "# epochs = 16\n",
    "# lr = 1e-3\n",
    "# z_dim = 16\n",
    "# seq_len = 5000\n",
    "\n",
    "# # Dataset & Loader\n",
    "# ds = ECGDataset(PTB_DIR, CH_DIR, sample_length=seq_len)\n",
    "# loader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# # Model, optim\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# vae = ECG_VAE(z_dim=z_dim, seq_len=seq_len).to(device)\n",
    "# opt = optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "# # Train\n",
    "# for ep in range(1, epochs+1):\n",
    "#     vae.train()\n",
    "#     tot_loss = 0\n",
    "#     for batch in loader:\n",
    "#         x = batch.to(device)\n",
    "#         x_hat, mu, logv = vae(x)\n",
    "#         loss, recon, kld = loss_fn(x, x_hat, mu, logv)\n",
    "#         opt.zero_grad(); loss.backward(); opt.step()\n",
    "#         tot_loss += loss.item()\n",
    "#     print(f\"Epoch {ep}/{epochs} - Loss: {tot_loss/len(loader):.4f} (Recon {recon:.4f}, KLD {kld:.4f})\")\n",
    "# # Guardar\n",
    "# torch.save(vae.state_dict(), 'ecg_vae.pth')\n",
    "# print(\"Modelo guardado en ecg_vae.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1b77f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.io import loadmat\n",
    "import wfdb\n",
    "from wfdb import rdrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "449dc577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from VAE import ECGDataset, ECG_VAE, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fea1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTB_DIR='data/ptb-xl'; CH_DIR='data/ChapmanShaoxing'\n",
    "# batch=16; epochs=15; lr=1e-3; z_dim=16; seq_len=5000\n",
    "# # dataset completo\n",
    "# ds=ECGDataset(PTB_DIR,CH_DIR,seq_len)\n",
    "# # split: 80% train, 10% val, 10% test\n",
    "# n=len(ds); n_test=int(0.1*n); n_val=int(0.1*n); n_train=n-n_val-n_test\n",
    "# ds_train, ds_val, ds_test = random_split(ds, [n_train,n_val,n_test])\n",
    "# loader_tr=DataLoader(ds_train,batch,shuffle=True,num_workers=4)\n",
    "# loader_val=DataLoader(ds_val,batch,shuffle=False,num_workers=2)\n",
    "\n",
    "# device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# vae=ECG_VAE(z_dim=z_dim, seq_len=seq_len).to(device)\n",
    "# opt=optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "# best_val=float('inf')\n",
    "# for ep in range(1,epochs+1):\n",
    "#     vae.train(); train_loss=0\n",
    "#     for xb in loader_tr:\n",
    "#         xb=xb.to(device)\n",
    "#         xh, mu, lv=vae(xb)\n",
    "#         loss,_,_ = loss_fn(xb,xh,mu,lv)\n",
    "#         opt.zero_grad(); loss.backward();\n",
    "#         nn.utils.clip_grad_norm_(vae.parameters(),1.0)\n",
    "#         opt.step(); train_loss+=loss.item()\n",
    "#     train_loss/=len(loader_tr)\n",
    "#     # validación\n",
    "#     vae.eval(); val_loss=0\n",
    "#     with torch.no_grad():\n",
    "#         for xb in loader_val:\n",
    "#             xb=xb.to(device)\n",
    "#             xh,mu,lv=vae(xb)\n",
    "#             loss,_,_=loss_fn(xb,xh,mu,lv)\n",
    "#             val_loss+=loss.item()\n",
    "#     val_loss/=len(loader_val)\n",
    "#     print(f\"Epoch {ep}/{epochs} - Train L: {train_loss:.4f}  Val L: {val_loss:.4f}\")\n",
    "#     if val_loss<best_val:\n",
    "#         best_val=val_loss\n",
    "#         torch.save(vae.state_dict(),'ecg_vae_best.pth')\n",
    "# print(\"Entrenamiento completo. Mejor modelo en ecg_vae_best.pth\")\n",
    "# # test: MAE sobre ds_test\n",
    "# from torch.utils.data import DataLoader\n",
    "# loader_te=DataLoader(ds_test,batch,shuffle=False)\n",
    "# tot_mae=[]\n",
    "# vae.load_state_dict(torch.load('ecg_vae_best.pth',map_location=device))\n",
    "# vae.eval()\n",
    "# with torch.no_grad():\n",
    "#     for xb in loader_te:\n",
    "#         xb=xb.to(device)\n",
    "#         xh,_,_=vae(xb)\n",
    "#         mae=torch.abs(xh-xb).mean(dim=(1,2)).cpu().numpy()\n",
    "#         tot_mae.extend(mae.tolist())\n",
    "# print(f\"MAE promedio normales test: {np.mean(tot_mae):.4f}\")\n",
    "# # ds_test contiene sólo normales. Anómalos se evalúan en script aparte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c99bd94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAEnew import ECGDataset, ECG_VAE, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fc13a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 1.1233  Val Loss: 1.0313\n",
      "Epoch 2/20 - Train Loss: 1.0081  Val Loss: 1.0025\n",
      "Epoch 3/20 - Train Loss: 1.0011  Val Loss: 1.0006\n",
      "Epoch 4/20 - Train Loss: 1.0005  Val Loss: 1.0002\n",
      "Epoch 5/20 - Train Loss: 1.0002  Val Loss: 1.0001\n",
      "Epoch 6/20 - Train Loss: 1.0001  Val Loss: 1.0001\n",
      "Epoch 7/20 - Train Loss: 1.0001  Val Loss: 1.0001\n",
      "Epoch 8/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 9/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 10/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 11/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 12/20 - Train Loss: 1.0000  Val Loss: 1.0002\n",
      "Epoch 13/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 14/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 15/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 16/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 17/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 18/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 19/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Epoch 20/20 - Train Loss: 1.0000  Val Loss: 1.0000\n",
      "Entrenamiento completo. Mejor modelo guardado en ecg_vae_best.pth\n",
      "Test Normales - MSE mean: 1.0000, KLD mean: 0.0000\n"
     ]
    }
   ],
   "source": [
    "PTB_DIR, CH_DIR = 'data/ptb-xl', 'data/ChapmanShaoxing'\n",
    "batch_size, seq_len, z_dim = 16, 5000, 16\n",
    "epochs, lr, beta = 20, 1e-4, 5.0\n",
    "\n",
    "# Dataset y splits\n",
    "ds = ECGDataset(PTB_DIR, CH_DIR, sample_length=seq_len)\n",
    "n = len(ds)\n",
    "n_test = int(0.1 * n)\n",
    "n_val = int(0.1 * n)\n",
    "n_train = n - n_val - n_test\n",
    "ds_tr, ds_val, ds_test = random_split(ds, [n_train, n_val, n_test])\n",
    "loader_tr = DataLoader(ds_tr, batch_size, shuffle=True, num_workers=4)\n",
    "loader_val= DataLoader(ds_val, batch_size, shuffle=False, num_workers=2)\n",
    "loader_te = DataLoader(ds_test, batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vae = ECG_VAE(in_ch=12, z_dim=z_dim, seq_len=seq_len).to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(1, epochs+1):\n",
    "    # Entrenamiento\n",
    "    vae.train()\n",
    "    train_loss = 0.0\n",
    "    for xb in loader_tr:\n",
    "        xb = xb.to(device)\n",
    "        xh, mu, logv = vae(xb)\n",
    "        loss, recon, kld = loss_fn(xb, xh, mu, logv, beta)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(vae.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(loader_tr)\n",
    "\n",
    "    # Validación\n",
    "    vae.eval()\n",
    "    val_loss, recs, klds = 0.0, [], []\n",
    "    with torch.no_grad():\n",
    "        for xb in loader_val:\n",
    "            xb = xb.to(device)\n",
    "            xh, mu, logv = vae(xb)\n",
    "            loss, recon, kld = loss_fn(xb, xh, mu, logv, beta)\n",
    "            val_loss += loss.item()\n",
    "            recs.append(recon.item())\n",
    "            klds.append(kld.item())\n",
    "    val_loss /= len(loader_val)\n",
    "    # Guardar mejor modelo\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(vae.state_dict(), 'ecg_vae_best.pth')\n",
    "        np.save('val_scores.npy', np.stack([recs, klds], axis=1))\n",
    "        mus = []\n",
    "        with torch.no_grad():\n",
    "            for xb in loader_val:\n",
    "                xb = xb.to(device)\n",
    "                _, mu_batch, _ = vae(xb)\n",
    "                mus.append(mu_batch.cpu().numpy())\n",
    "        np.save('val_mu.npy', np.concatenate(mus, axis=0))\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Entrenamiento completo. Mejor modelo guardado en ecg_vae_best.pth\")\n",
    "\n",
    "# Test finales (normales)\n",
    "vae.load_state_dict(torch.load('ecg_vae_best.pth', map_location=device))\n",
    "te_recs, te_klds = [], []\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    for xb in loader_te:\n",
    "        xb = xb.to(device)\n",
    "        xh, mu, logv = vae(xb)\n",
    "        mse_vals = nn.functional.mse_loss(xh, xb, reduction='none').mean(dim=(1,2))\n",
    "        kld_vals = (-0.5 * torch.sum(1 + logv - mu.pow(2) - logv.exp(), dim=1))\n",
    "        te_recs.extend(mse_vals.cpu().numpy())\n",
    "        te_klds.extend(kld_vals.cpu().numpy())\n",
    "np.save('test_scores.npy', np.stack([te_recs, te_klds], axis=1))\n",
    "mus_test = []\n",
    "with torch.no_grad():\n",
    "    for xb in loader_te:\n",
    "        xb = xb.to(device)\n",
    "        _, mu_batch, _ = vae(xb)\n",
    "        mus_test.append(mu_batch.cpu().numpy())\n",
    "np.save('test_mu.npy', np.concatenate(mus_test, axis=0))\n",
    "print(f\"Test Normales - MSE mean: {np.mean(te_recs):.4f}, KLD mean: {np.mean(te_klds):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP-final_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
